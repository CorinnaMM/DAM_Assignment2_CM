#write dataframe to disk to check
write.csv(Ionosphere,"Ionosphere.csv")
#separate training and test sets
trainset <- Ionosphere[Ionosphere$train==1,]
testset <- Ionosphere[Ionosphere$train==0,]
trainColNum <- grep("train",names(trainset))
#predicted variable is Class
typeColNum <- grep("Class",names(Ionosphere))
trainset <- trainset[,-trainColNum]
testset <- testset[,-trainColNum]
#build tree
#default params. This is a classification problem so set method="class"
rpart_model <- rpart(Class~.,data = trainset, method="class")
#plot tree - SAVE PLOT for comparison later
#plot(rpart_model);text(rpart_model)
#prp from rpart.plot produces nicer plots
prp(rpart_model)
#summary
summary(rpart_model)
#predict on test data
rpart_predict <- predict(rpart_model,testset[,-typeColNum],type="class")
#write predictions to disk
test_predictions_dt1 <- data.frame(testset,rpart_predict)
write.csv(test_predictions_dt1,file="test_predictions_dt.csv")
#accuracy
mean(rpart_predict==testset$Class)
#confusion matrix
table(pred=rpart_predict,true=testset$Class)
#Now rerun for different values of seed (say 53 and 1)  and re-plot tree, calculate
#accuracy and confusion matrix for each. Comment on the plots.
?glm
?glmnet
library(glmnet)
?glmnet
?rf
?rpart
??rpart
?rf
library(randomForest)
?randomForest
?glmnet
library(glmnet)
?glmnet
?tuneGrid
??tuneGrid
library(caret)
?tuneGrid
library(caret)
library(parallel)
library(doParallel)
# set up cluster for parallel computing
cluster = makeCluster(detectCores() - 1)
registerDoParallel(cluster)
# Load the German Credit data (from caret)
data(GermanCredit)
# reorder the levels of Class so that "Good" is our 0, "Bad" is our 1
GermanCredit$Class = factor(GermanCredit$Class, c("Good","Bad"))
set.seed(42)
index = createDataPartition(y = GermanCredit$Class, p = 0.7, list = F)
training = GermanCredit[index, ]
testing = GermanCredit[-index, ]
ctrl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE)
gbm_grid = expand.grid(interaction.depth = c(3,5),
n.trees = c(200, 300),
shrinkage = 0.05,
n.minobsinnode = c(10,20))
set.seed(42)
gbm_fit = train(x = training[, -10], y = training$Class,
method = "gbm",
trControl = ctrl,
tuneGrid = gbm_grid,
metric = "ROC")
gbm_fit$results
print(gbm_fit)
gbm_pred = predict(gbm_fit, testing, type = "raw")
confusionMatrix(gbm_pred, testing$Class, mode = "everything", positive="Bad")
testing$probability = predict(gbm_fit, testing, type = "prob")[, 1]
training$probability = predict(gbm_fit, training, type = "prob")[, 1]
gbm_importance = varImp(gbm_fit)$importance
gbm_importance$variable = rownames(gbm_importance)
gbm_importance = gbm_importance[order(gbm_importance$Overall, decreasing = T), ]$variable
# partial dependence plots
par(mfrow = c(2,2))
for (var in gbm_importance[1:length(gbm_importance)]) {
plot.gbm(gbm_fit$finalModel, i.var = var, type = "response")
}
source("model_evaluation.R")
threshold = model_evaluation(training = training, testing = testing,
model = gbm_fit,
target = "Class")
library(caret)
library(parallel)
library(doParallel)
cluster = makeCluster(detectCores() - 1)
registerDoParallel(cluster)
# Load the German Credit data (from caret)
data(GermanCredit)
# reorder the levels of Class so that "Good" is our 0, "Bad" is our 1
GermanCredit$Class = factor(GermanCredit$Class, c("Good","Bad"))
set.seed(42)
index = createDataPartition(y = GermanCredit$Class, p = 0.7, list = F)
training = GermanCredit[index, ]
testing = GermanCredit[-index, ]
ctrl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE)
gbm_grid = expand.grid(interaction.depth = c(3,5),
n.trees = c(200, 300),
shrinkage = 0.05,
n.minobsinnode = c(10,20))
set.seed(42)
gbm_fit = train(x = training[, -10], y = training$Class,
method = "gbm",
trControl = ctrl,
tuneGrid = gbm_grid,
metric = "ROC")
gbm_fit$results
print(gbm_fit)
gbm_pred = predict(gbm_fit, testing, type = "raw")
confusionMatrix(gbm_pred, testing$Class, mode = "everything", positive="Bad")
testing$probability = predict(gbm_fit, testing, type = "prob")[, 1]
training$probability = predict(gbm_fit, training, type = "prob")[, 1]
gbm_importance = varImp(gbm_fit)$importance
gbm_importance$variable = rownames(gbm_importance)
gbm_importance = gbm_importance[order(gbm_importance$Overall, decreasing = T), ]$variable
# partial dependence plots
par(mfrow = c(2,2))
for (var in gbm_importance[1:length(gbm_importance)]) {
plot.gbm(gbm_fit$finalModel, i.var = var, type = "response")
}
source("model_evaluation.R")
threshold = model_evaluation(training = training, testing = testing,
model = gbm_fit,
target = "Class")
df$Target = make.names(df$Target)
set.seed(42)
train = createDataPartition(y = df$Target, p = 0.7, list = F)
# drop ID column
training = df[train,]
testing = df[-train,]
trainControl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
#random forrest hyperparams
rf_hyperparams = expand.grid(mtry = c(4,5,6))
# need to fix this
set.seed(42)
x_train <- model.matrix( ~ ., training[,-14])
rf_fit = train(x = x_train, y = training$loan_status,
method = "rf",
trControl = trainControl,
tuneGrid = rf_hyperparams,
metric = "ROC")
rf_fit$results
print(rf_fit)
rf_pred = predict(rf_fit, testing, type = "raw")
confusionMatrix(rf_pred, testing$loan_status, mode = "everything", positive="Charged.Off")
testing$probability = predict(rf_fit, testing, type = "prob")[, 1]
training$probability = predict(rf_fit, training, type = "prob")[, 1]
rf_importance = varImp(rf_fit)$importance
#rf_importance$variable = rownames(rf_importance)
#rf_importance = rf_importance[order(rf_importance$Overall, decreasing = T), ]$variable
rf_importance
# partial dependence plots
par(mfrow = c(2,2))
counter = 0
for (i in seq_along(rf_importance)[1:14]) {
counter = counter + 1
partialPlot(x = rf_fit$finalModel, pred.data = training, x.var = rf_importance[i],
main = paste("Partial Dependence on", rf_importance[i]),
xlab = rf_importance[i], col = "red",
which.class = "X1")
}
#validation data set
validation = read.csv("repurchase_validation.csv")
validation$validation_pred = predict(rf_fit, validation, type = "raw")
validation$probability = predict(rf_fit, validation, type = "prob")[, 1]
write.csv(validation, "validation.csv")
count(validation$validation_pred)
library(dplyr)
library(plyr)
library(ggplot2)
library(caret)
library(pls)
library(xgboost)
library(parallel)
library(doParallel)
# set up cluster for parallel computing
cluster = makeCluster(detectCores() - 1)
registerDoParallel(cluster)
setwd("~/Documents/GitHub/DAM_Assignment2_CM/01_Code")
raw_df = read.csv("~/Documents/GitHub/DAM_Assignment2_CM/02_Working_data_folder/clean_data_v5.csv")
df = raw_df
#basic exploration
head(df, 10)
tail(df, 10)
dim(df)
str(df)
summary(df)
#frequency of target and non-target variable
count(df$loan_status)
#check for duplicated values
sum(duplicated(df)==TRUE)
pca_var <- c(2,3,4,7,25:28)
pcadf = df[,pca_var]
str(df)
str(pcadf)
pr_out = prcomp(df[,pca_var], scale = T)
names(pr_out)
pr_out$rotation
#biplot(pr_out)
#scree plot
pr_var = pr_out$sdev ^ 2
pve = pr_var/sum(pr_var)
plot(pve, type = "b", main ="Scree Plot",
ylab = "Proportion of Variance Explained",
xlab = "Principal Component")
plot(cumsum(pve), type = 'b', main = "Cumulative Variance Explained",
xlab = "Number of Components",
ylab = "Cumulative Proportion of Variance Explained")
#come back to this and revaluate groupings
set.seed(42)
train = createDataPartition(y = df$Target, p = 0.7, list = F)
# drop ID column
training = df[train,]
testing = df[-train,]
trainControl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
#random forrest hyperparams
rf_hyperparams = expand.grid(mtry = c(4,5,6))
# need to fix this
set.seed(42)
x_train <- model.matrix( ~ ., training[,-14])
rf_fit = train(x = x_train, y = training$loan_status,
method = "rf",
trControl = trainControl,
tuneGrid = rf_hyperparams,
metric = "ROC")
rf_fit$results
print(rf_fit)
rf_pred = predict(rf_fit, testing, type = "raw")
confusionMatrix(rf_pred, testing$loan_status, mode = "everything", positive="Charged.Off")
testing$probability = predict(rf_fit, testing, type = "prob")[, 1]
training$probability = predict(rf_fit, training, type = "prob")[, 1]
rf_importance = varImp(rf_fit)$importance
#rf_importance$variable = rownames(rf_importance)
#rf_importance = rf_importance[order(rf_importance$Overall, decreasing = T), ]$variable
rf_importance
# partial dependence plots
par(mfrow = c(2,2))
counter = 0
for (i in seq_along(rf_importance)[1:14]) {
counter = counter + 1
partialPlot(x = rf_fit$finalModel, pred.data = training, x.var = rf_importance[i],
main = paste("Partial Dependence on", rf_importance[i]),
xlab = rf_importance[i], col = "red",
which.class = "X1")
}
#validation data set
validation = read.csv("repurchase_validation.csv")
validation$validation_pred = predict(rf_fit, validation, type = "raw")
validation$probability = predict(rf_fit, validation, type = "prob")[, 1]
write.csv(validation, "validation.csv")
count(validation$validation_pred)
set.seed(42)
train = createDataPartition(y = df$Target, p = 0.7, list = F)
# drop ID column
training = df[train,]
testing = df[-train,]
trainControl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
#random forrest hyperparams
rf_hyperparams = expand.grid(mtry = c(4,5,6))
# need to fix this
set.seed(42)
x_train <- model.matrix( ~ ., training[,-14])
rf_fit = train(x = x_train, y = training$loan_status,
method = "rf",
trControl = trainControl,
tuneGrid = rf_hyperparams,
metric = "ROC")
set.seed(42)
train = createDataPartition(y = df$Target, p = 0.7, list = F)
# drop ID column
training = df[train,]
testing = df[-train,]
trainControl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
#random forrest hyperparams
rf_hyperparams = expand.grid(mtry = c(4,5,6))
# need to fix this
set.seed(42)
x_train <- model.matrix( ~ ., training[,-14])
library(dplyr)
library(plyr)
library(ggplot2)
library(caret)
library(pls)
library(xgboost)
library(parallel)
library(doParallel)
# set up cluster for parallel computing
cluster = makeCluster(detectCores() - 1)
registerDoParallel(cluster)
setwd("~/Documents/GitHub/DAM_Assignment2_CM/01_Code")
raw_df = read.csv("~/Documents/GitHub/DAM_Assignment2_CM/02_Working_data_folder/clean_data_v5.csv")
df = raw_df
#basic exploration
head(df, 10)
tail(df, 10)
dim(df)
str(df)
summary(df)
#frequency of target and non-target variable
count(df$loan_status)
#check for duplicated values
sum(duplicated(df)==TRUE)
pca_var <- c(2,3,4,7,25:28)
pcadf = df[,pca_var]
str(df)
str(pcadf)
pr_out = prcomp(df[,pca_var], scale = T)
names(pr_out)
pr_out$rotation
#biplot(pr_out)
#scree plot
pr_var = pr_out$sdev ^ 2
pve = pr_var/sum(pr_var)
plot(pve, type = "b", main ="Scree Plot",
ylab = "Proportion of Variance Explained",
xlab = "Principal Component")
plot(cumsum(pve), type = 'b', main = "Cumulative Variance Explained",
xlab = "Number of Components",
ylab = "Cumulative Proportion of Variance Explained")
#come back to this and revaluate groupings
set.seed(42)
train = createDataPartition(y = df$Target, p = 0.7, list = F)
# drop ID column
training = df[train,]
testing = df[-train,]
trainControl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
#gradient boosted hyperparams
lasso_hyperparams = expand.grid(alpha = 1,
lambda = seq(0.0001, 1, length = 100))
x_train <- model.matrix( ~ ., training[,-14])
lasso_fit = train(x = x_train, y = training$loan_status,
method='glmnet',
trControl= trainControl,
tuneGrid = lasso_hyperparams,
metric = "ROC" )
print(lasso_fit)
newx = model.matrix( ~ ., testing[,-14])
lasso_pred = predict(lasso_fit, newx, type = "raw")
confusionMatrix(data = lasso_pred, testing$loan_status, mode = "everything", positive="Charged.Off")
testing$probability = predict(lasso_fit, newx, type = "prob")[, 1]
training$probability = predict(lasso_fit, x_train, type = "prob")[, 1]
train = createDataPartition(y = df$Target, p = 0.7, list = F)
library(dplyr)
library(plyr)
library(ggplot2)
library(caret)
library(pls)
library(xgboost)
library(parallel)
library(doParallel)
# set up cluster for parallel computing
cluster = makeCluster(detectCores() - 1)
registerDoParallel(cluster)
setwd("~/Documents/GitHub/DAM_Assignment2_CM/01_Code")
raw_df = read.csv("~/Documents/GitHub/DAM_Assignment2_CM/02_Working_data_folder/clean_data_v5.csv")
df = raw_df
#basic exploration
head(df, 10)
tail(df, 10)
dim(df)
str(df)
summary(df)
#frequency of target and non-target variable
count(df$loan_status)
#check for duplicated values
sum(duplicated(df)==TRUE)
pca_var <- c(2,3,4,7,25:28)
pcadf = df[,pca_var]
str(df)
str(pcadf)
pr_out = prcomp(df[,pca_var], scale = T)
names(pr_out)
pr_out$rotation
#biplot(pr_out)
#scree plot
pr_var = pr_out$sdev ^ 2
pve = pr_var/sum(pr_var)
plot(pve, type = "b", main ="Scree Plot",
ylab = "Proportion of Variance Explained",
xlab = "Principal Component")
plot(cumsum(pve), type = 'b', main = "Cumulative Variance Explained",
xlab = "Number of Components",
ylab = "Cumulative Proportion of Variance Explained")
#come back to this and revaluate groupings
set.seed(42)
train = createDataPartition(y = df$Target, p = 0.7, list = F)
# drop ID column
training = df[train,]
testing = df[-train,]
trainControl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
#gradient boosted hyperparams
lasso_hyperparams = expand.grid(alpha = 1,
lambda = seq(0.0001, 1, length = 100))
x_train <- model.matrix( ~ ., training[,-14])
lasso_fit = train(x = x_train, y = training$loan_status,
method='glmnet',
trControl= trainControl,
tuneGrid = lasso_hyperparams,
metric = "ROC" )
print(lasso_fit)
newx = model.matrix( ~ ., testing[,-14])
lasso_pred = predict(lasso_fit, newx, type = "raw")
confusionMatrix(data = lasso_pred, testing$loan_status, mode = "everything", positive="Charged.Off")
testing$probability = predict(lasso_fit, newx, type = "prob")[, 1]
training$probability = predict(lasso_fit, x_train, type = "prob")[, 1]
train = createDataPartition(y = df$loan_status, p = 0.7, list = F)
training = df[train,]
testing = df[-train,]
trainControl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
#gradient boosted hyperparams
lasso_hyperparams = expand.grid(alpha = 1,
lambda = seq(0.0001, 1, length = 100))
x_train <- model.matrix( ~ ., training[,-14])
lasso_fit = train(x = x_train, y = training$loan_status,
method='glmnet',
trControl= trainControl,
tuneGrid = lasso_hyperparams,
metric = "ROC" )
print(lasso_fit)
newx = model.matrix( ~ ., testing[,-14])
lasso_pred = predict(lasso_fit, newx, type = "raw")
confusionMatrix(data = lasso_pred, testing$loan_status, mode = "everything", positive="Charged.Off")
testing$probability = predict(lasso_fit, newx, type = "prob")[, 1]
training$probability = predict(lasso_fit, x_train, type = "prob")[, 1]
df$Target = make.names(df$Target)
set.seed(42)
train = createDataPartition(y = df$Target, p = 0.7, list = F)
# drop ID column
training = df[train,]
testing = df[-train,]
trainControl = trainControl(method = "cv",
number = 5,
classProbs = T,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
#random forrest hyperparams
rf_hyperparams = expand.grid(mtry = c(4,5,6))
# need to fix this
set.seed(42)
x_train <- model.matrix( ~ ., training[,-14])
rf_fit = train(x = x_train, y = training$loan_status,
method = "rf",
trControl = trainControl,
tuneGrid = rf_hyperparams,
metric = "ROC")
rf_fit$results
print(rf_fit)
rf_pred = predict(rf_fit, testing, type = "raw")
confusionMatrix(rf_pred, testing$loan_status, mode = "everything", positive="Charged.Off")
testing$probability = predict(rf_fit, testing, type = "prob")[, 1]
training$probability = predict(rf_fit, training, type = "prob")[, 1]
rf_importance = varImp(rf_fit)$importance
#rf_importance$variable = rownames(rf_importance)
#rf_importance = rf_importance[order(rf_importance$Overall, decreasing = T), ]$variable
rf_importance
confusionMatrix(rf_pred, testing$loan_status, mode = "everything", positive="Charged.Off")
rf_pred = predict(rf_fit, testing, type = "raw")
newx = model.matrix( ~ ., testing[,-14])
rf_pred = predict(rf_fit, newx, type = "raw")
confusionMatrix(rf_pred, testing$loan_status, mode = "everything", positive="Charged.Off")
